{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "일별시세 페이지 분석"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_cd = 'KPI200'\n",
    "page_n = 1\n",
    "naver_index = 'http://finance.naver.com/sise/sise_index_day.nhn?code=' + index_cd + '&page=' + str(page_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from urllib.request import urlopen  \n",
    "source = urlopen(naver_index).read()\n",
    "source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bs4\n",
    "source = bs4.BeautifulSoup(source, 'lxml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(source.prettify())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "td = source.find_all('td')\n",
    "len(td)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "날짜 추출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# /html/body/div/table[1]/tbody/tr[3]/td[1]\n",
    "source.find_all('table')[0].find_all('tr')[2].find_all('td')[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = source.find_all('td', class_='date')[0].text\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime as dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yyyy = int(d.split('.')[0]) \n",
    "mm = int(d.split('.')[1])\n",
    "dd = int(d.split('.')[2])\n",
    "\n",
    "this_date= dt.date(yyyy, mm, dd)\n",
    "this_date"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "날짜정보를  date 타입으로 변경하는 함수 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def date_format(d):\n",
    "    d = str(d).replace('-', '.')\n",
    "    \n",
    "    yyyy = int(d.split('.')[0]) \n",
    "    mm = int(d.split('.')[1])\n",
    "    dd = int(d.split('.')[2])\n",
    "\n",
    "    this_date= dt.date(yyyy, mm, dd)\n",
    "    return this_date"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "종가 추출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# /html/body/div/table[1]/tbody/tr[3]/td[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "this_close = source.find_all('tr')[2].find_all('td')[1].text\n",
    "this_close = this_close.replace(',', '')\n",
    "this_close = float(this_close)\n",
    "this_close"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = source.find_all('td', class_='number_1')[0].text\n",
    "p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "페이지 상의 날짜와 종가정보 전체 추출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dates = source.find_all('td', class_='date')\n",
    "prices = source.find_all('td', class_='number_1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(dates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(prices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for n in range(len(dates)):\n",
    "    this_date = dates[n].text\n",
    "    this_date = date_format(this_date)\n",
    "    \n",
    "    this_close = prices[n*4].text   \n",
    "    # 0, 4, 8, ... 4의 배수로 돌아가는 가격 추출\n",
    "    this_close = this_close.replace(',', '')\n",
    "    this_close = float(this_close)\n",
    "    this_close\n",
    "    \n",
    "    print(this_date, this_close)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "마지막 페이지 번호 찾기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# /html/body/div/table[2]/tbody/tr/td[7]/a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "paging = source.find('td', class_='pgRR').find('a')['href']\n",
    "paging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paging = paging.split('&')[1]\n",
    "paging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paging = paging.split('=')[1]\n",
    "paging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "naver_index = 'http://finance.naver.com/sise/sise_index_day.nhn?code=' + index_cd + '&page=' + str(505)\n",
    "\n",
    "source = urlopen(naver_index).read()\n",
    "source = bs4.BeautifulSoup(source, 'lxml')\n",
    "\n",
    "if source.find('td', class_='pgRR'):\n",
    "    last_page = source.find('td', class_='pgRR').find('a')['href']\n",
    "    last_page = last_page.split('&')[1]\n",
    "    last_page = last_page.split('=')[1]\n",
    "    last_page = int(last_page)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def historical_index_naver(index_cd, page_n=1, last_page=0):   \n",
    "        \n",
    "    naver_index = 'http://finance.naver.com/sise/sise_index_day.nhn?code=' + index_cd + '&page=' + str(page_n)\n",
    "    \n",
    "    source = urlopen(naver_index).read()   # 지정한 페이지에서 코드 읽기\n",
    "    source = bs4.BeautifulSoup(source, 'lxml')   # 뷰티풀 스프로 태그별로 코드 분류\n",
    "    \n",
    "    dates = source.find_all('td', class_='date')   # <td class=\"date\">태그에서 날짜 수집   \n",
    "    prices = source.find_all('td', class_='number_1')   # <td class=\"number_1\">태그에서 지수 수집\n",
    "    \n",
    "    for n in range(len(dates)):\n",
    "    \n",
    "        if dates[n].text.split('.')[0].isdigit():\n",
    "            \n",
    "            # 날짜 처리\n",
    "            this_date = dates[n].text\n",
    "            this_date= date_format(this_date)\n",
    "            \n",
    "            # 종가 처리\n",
    "            this_close = prices[n*4].text   # prices 중 종가지수인 0,4,8,...번째 데이터 추출\n",
    "            this_close = this_close.replace(',', '')\n",
    "            this_close = float(this_close)\n",
    "\n",
    "            # 딕셔너리에 저장\n",
    "            historical_prices[this_date] = this_close\n",
    "            \n",
    "    # 페이지 네비게이션\n",
    "    if last_page == 0:\n",
    "        last_page = source.find('td', class_='pgRR').find('a')['href']\n",
    "        # 마지막페이지 주소 추출\n",
    "        last_page = last_page.split('&')[1]   # & 뒤의 page=506 부분 추출\n",
    "        last_page = last_page.split('=')[1]   # = 뒤의 페이지번호만 추출\n",
    "        last_page = int(last_page)   # 숫자형 변수로 변환\n",
    "        \n",
    "    # 다음 페이지 호출\n",
    "    if page_n < last_page:   \n",
    "        page_n = page_n + 1   \n",
    "        historical_index_naver(index_cd, start_date, end_date, page_n, last_page)   \n",
    "        \n",
    "    return historical_prices  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "네이버에서 일자별 인덱스를 추출하는 함수 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def historical_index_naver(index_cd, start_date='', end_date='', page_n=1, last_page=0):\n",
    "    \n",
    "    if start_date:   # start_date가 있으면\n",
    "        start_date = date_format(start_date)   # date 포맷으로 변환\n",
    "    else:    # 없으면\n",
    "        start_date = dt.date.today()   # 오늘 날짜를 지정\n",
    "    if end_date:   \n",
    "        end_date = date_format(end_date)   \n",
    "    else:   \n",
    "        end_date = dt.date.today()  \n",
    "        \n",
    "        \n",
    "    naver_index = 'http://finance.naver.com/sise/sise_index_day.nhn?code=' + index_cd + '&page=' + str(page_n)\n",
    "    \n",
    "    source = urlopen(naver_index).read()   # 지정한 페이지에서 코드 읽기\n",
    "    source = bs4.BeautifulSoup(source, 'lxml')   # 뷰티풀 스프로 태그별로 코드 분류\n",
    "    \n",
    "    dates = source.find_all('td', class_='date')   # <td class=\"date\">태그에서 날짜 수집   \n",
    "    prices = source.find_all('td', class_='number_1')   # <td class=\"number_1\">태그에서 지수 수집\n",
    "    \n",
    "    for n in range(len(dates)):\n",
    "    \n",
    "        if dates[n].text.split('.')[0].isdigit():\n",
    "            \n",
    "            # 날짜 처리\n",
    "            this_date = dates[n].text\n",
    "            this_date= date_format(this_date)\n",
    "            \n",
    "            if this_date <= end_date and this_date >= start_date:   \n",
    "            # start_date와 end_date 사이에서 데이터 저장\n",
    "                # 종가 처리\n",
    "                this_close = prices[n*4].text   # prices 중 종가지수인 0,4,8,...번째 데이터 추출\n",
    "                this_close = this_close.replace(',', '')\n",
    "                this_close = float(this_close)\n",
    "\n",
    "                # 딕셔너리에 저장\n",
    "                historical_prices[this_date] = this_close\n",
    "                \n",
    "            elif this_date < start_date:   \n",
    "            # start_date 이전이면 함수 종료\n",
    "                return historical_prices              \n",
    "            \n",
    "    # 페이지 네비게이션\n",
    "    if last_page == 0:\n",
    "        last_page = source.find('td', class_='pgRR').find('a')['href']\n",
    "        # 마지막페이지 주소 추출\n",
    "        last_page = last_page.split('&')[1]   # & 뒤의 page=506 부분 추출\n",
    "        last_page = last_page.split('=')[1]   # = 뒤의 페이지번호만 추출\n",
    "        last_page = int(last_page)   # 숫자형 변수로 변환\n",
    "        \n",
    "    # 다음 페이지 호출\n",
    "    if page_n < last_page:   \n",
    "        page_n = page_n + 1   \n",
    "        historical_index_naver(index_cd, start_date, end_date, page_n, last_page)   \n",
    "        \n",
    "    return historical_prices  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "index_cd = 'KPI200'\n",
    "historical_prices = dict()\n",
    "historical_index_naver(index_cd, '2021-4-1', '2021-4-4')\n",
    "historical_prices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 다음에서 해외지수 추출 (다음 사이트 개편으로 네이버로 대체합니다)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "본 섹션의 내용은 다음 금융사이트 개편으로 사용이 불가해져, 네이버에서 해외지수 추출로 대체합니다."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "url = 'http://finance.daum.net/global/index_daily.daum?type=default&ric=/.GSPC&page=1' \n",
    "    \n",
    "source = urlopen(url).read()\n",
    "source = bs4.BeautifulSoup(source, 'lxml')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "dates = source.find_all('td', class_='datetime')\n",
    "dates"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "prices = source.find_all('td', class_='num')\n",
    "print(len(dates))\n",
    "print(len(prices))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "prices[0].text"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "def historical_global_daum(index_cd, start_date='', end_date='', page_n=1, last_page=0):\n",
    "    \n",
    "    if start_date:   # start_date가 있으면\n",
    "        start_date = date_format(start_date)   # date 포맷으로 변환\n",
    "    else:    # 없으면\n",
    "        start_date = dt.date.today()   # 오늘 날짜를 지정\n",
    "    if end_date:  \n",
    "        end_date = date_format(end_date)   \n",
    "    else:   \n",
    "        end_date = dt.date.today()  \n",
    "    \n",
    "    url = 'http://finance.daum.net/global/index_daily.daum?type=default&ric=/.' + index_cd + '&page=' + str(page_n)\n",
    "\n",
    "    source = urlopen(url).read()\n",
    "    source = bs4.BeautifulSoup(source, 'lxml')\n",
    "\n",
    "    dates = source.find_all('td', class_='datetime')   # <td class=\"datetime\">태그에서 날짜 수집\n",
    "    prices = source.find_all('td', class_='num')   # <td class=\"num\">태그에서 날짜 수집\n",
    "\n",
    "    rows_in_page = len(dates)\n",
    "\n",
    "    if len(dates) > 0:\n",
    "\n",
    "        for n in range(rows_in_page):\n",
    "\n",
    "            # 날짜 처리\n",
    "            this_date = dates[n].text\n",
    "            this_date= date_format(this_date)\n",
    "\n",
    "            if this_date <= end_date and this_date >= start_date:   \n",
    "            # start_date와 end_date 사이에서 데이터 저장\n",
    "                # 종가 처리\n",
    "                this_close = prices[n*3].text\n",
    "                this_close = this_close.replace(' ', '')\n",
    "                this_close = this_close.replace('\\t', '')\n",
    "                this_close = this_close.replace('\\n', '')\n",
    "                this_close = this_close.replace(',', '')\n",
    "                this_close = float(this_close)\n",
    "\n",
    "                # 딕셔너리에 저장\n",
    "                historical_prices[this_date] = this_close\n",
    "                \n",
    "            elif this_date < start_date:   \n",
    "            # start_date 이전이면 함수 종료\n",
    "                return historical_prices                         \n",
    "        # 페이지 네비게이션\n",
    "        if rows_in_page == 10:\n",
    "            page_n = int(page_n)\n",
    "            page_n = page_n + 1\n",
    "            \n",
    "            historical_global_daum(index_cd, start_date, end_date, page_n, last_page)\n",
    "            \n",
    "    return historical_prices  "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "historical_prices = dict()\n",
    "daum = historical_global_daum('GSPC', '2018-4-1', '2018-4-5')\n",
    "daum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 네이버에서 해외지수 추출하기 (다음 해외지수 대체)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests, json   # 해외지수는 json 형태로 표출됨\n",
    "headers = {\n",
    "    'User-Agent': 'Mozilla/5.0',\n",
    "    'X-Requested-With': 'XMLHttpRequest',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "symbol = 'SPI@SPX'\n",
    "page = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://finance.naver.com/world/worldDayListJson.nhn?symbol='+symbol+'&fdtc=0&page='+str(page)\n",
    "r = requests.post(url, headers=headers)\n",
    "data = json.loads(r.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[0]['symb']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[0]['xymd']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[0]['clos']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = dict()\n",
    "for n in range(len(data)):\n",
    "    date = pd.to_datetime(data[n]['xymd']).date()\n",
    "    price = float(data[n]['clos'])\n",
    "    d[date] = price\n",
    "print(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_json(d, symbol, page=1):\n",
    "    url = 'https://finance.naver.com/world/worldDayListJson.nhn?symbol='+symbol+'&fdtc=0&page='+str(page)\n",
    "    r = requests.post(url, headers=headers)\n",
    "    data = json.loads(r.text)\n",
    "    \n",
    "    for n in range(len(data)):\n",
    "        date = pd.to_datetime(data[n]['xymd']).date()\n",
    "        price = float(data[n]['clos'])\n",
    "        d[date] = price\n",
    "        \n",
    "    if len(data) >= 9 and page<3:\n",
    "        page += 1\n",
    "        read_json(d, symbol, page)\n",
    "        \n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "historical_index = dict()\n",
    "historical_index = read_json(historical_index, symbol, page)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "historical_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = {\n",
    "    'SPI@SPX' : 'S&P 500', \n",
    "    'NAS@NDX' : 'Nasdaq 100', \n",
    "    'NII@NI225' : 'Nikkei 225',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "historical_indices = dict()\n",
    "for key, value in indices.items(): \n",
    "    print (key, value)\n",
    "    s = dict()\n",
    "    s = read_json(s, key, 1)\n",
    "    historical_indices[value] = s    \n",
    "prices_df = pd.DataFrame(historical_indices)\n",
    "prices_df.sort_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prices_df.tail(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def date_format(d=''):\n",
    "    if d != '':\n",
    "        this_date = pd.to_datetime(d).date()\n",
    "    else:\n",
    "        this_date = pd.Timestamp.today().date()   # 오늘 날짜를 지정\n",
    "    return (this_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def index_global(d, symbol, start_date='', end_date='', page=1):\n",
    "\n",
    "    end_date = date_format(end_date)\n",
    "    if start_date == '':\n",
    "        start_date = end_date - pd.DateOffset(months=1)\n",
    "    start_date = date_format(start_date)\n",
    "        \n",
    "    url = 'https://finance.naver.com/world/worldDayListJson.nhn?symbol='+symbol+'&fdtc=0&page='+str(page)\n",
    "    r = requests.post(url, headers=headers)\n",
    "    data = json.loads(r.text)\n",
    "    \n",
    "    if len(data) > 0:\n",
    "        \n",
    "        for n in range(len(data)):\n",
    "            date = pd.to_datetime(data[n]['xymd']).date()\n",
    "\n",
    "            if date <= end_date and date >= start_date:   \n",
    "            # start_date와 end_date 사이에서 데이터 저장\n",
    "                # 종가 처리\n",
    "                price = float(data[n]['clos'])\n",
    "                # 딕셔너리에 저장\n",
    "                d[date] = price\n",
    "            elif date < start_date:   \n",
    "            # start_date 이전이면 함수 종료\n",
    "                return d              \n",
    "\n",
    "        if len(data) >= 9:\n",
    "            page += 1\n",
    "            index_global(d, symbol, start_date, end_date, page)\n",
    "        \n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "historical_indices = dict()\n",
    "start_date = '2021-01-01'\n",
    "end_date = '2021-3-31'\n",
    "for key, value in indices.items(): \n",
    "    s = dict()\n",
    "    s = index_global(s, key, start_date, end_date)\n",
    "    historical_indices[value] = s    \n",
    "prices_df = pd.DataFrame(historical_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "prices_df[:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 만들어둔 함수를 이용해 KOSPI200과 S&P500 지수 추출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_cd = 'KPI200'\n",
    "historical_prices = dict()\n",
    "kospi200 = historical_index_naver(index_cd, '2020-1-1', '2020-12-31')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_cd = 'SPI@SPX'\n",
    "historical_prices = dict()\n",
    "sp500 = index_global(historical_prices, index_cd, '2020-1-1', '2020-12-31')    # 대체 코드\n",
    "# sp500 = historical_global_daum(index_cd, '2017-1-1', '2017-12-31')    # 이전 코드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = {'S&P500':sp500, 'KOSPI200':kospi200}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(tmp)\n",
    "df.sort_index(inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = df.fillna(method='ffill')\n",
    "if df.isnull().values.any():\n",
    "    df = df.fillna(method='bfill')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_cd = 'KPI200'\n",
    "historical_prices = dict()\n",
    "kospi200 = historical_index_naver(index_cd, '2020-1-1', '2021-12-31')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_cd = 'SPI@SPX'\n",
    "historical_prices = dict()\n",
    "sp500 = index_global(historical_prices, index_cd, '2020-1-1', '2021-12-31')    # 대체 코드\n",
    "# sp500 = historical_global_daum(index_cd, '2008-1-1', '2017-12-31')     # 이전 코드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = {'S&P500':sp500, 'KOSPI200':kospi200}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(tmp)\n",
    "df.sort_index(inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = df.fillna(method='ffill')\n",
    "if df.isnull().values.any():\n",
    "    df = df.fillna(method='bfill')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# matplotlib를 이용해 그래프 그리기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(df['S&P500'], label='S&P500')\n",
    "plt.plot(df['KOSPI200'], label='KOSPI200')\n",
    "plt.legend(loc=0)\n",
    "plt.grid(True, color='0.7', linestyle=':', linewidth=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[dt.date(2020, 1, 2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(df['S&P500'] / df['S&P500'].loc[dt.date(2020, 1, 2)] * 100, label='S&P500')\n",
    "plt.plot(df['KOSPI200'] / df['KOSPI200'].loc[dt.date(2020, 1, 2)] * 100, label='KOSPI200')\n",
    "plt.legend(loc=0)\n",
    "plt.grid(True, color='0.7', linestyle=':', linewidth=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ratio_2021_now = df.loc[dt.date(2021, 1, 1):] / df.loc[dt.date(2021, 1, 4)] * 100\n",
    "df_ratio_2021_now.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(df_ratio_2021_now['S&P500'], label='S&P500')\n",
    "plt.plot(df_ratio_2021_now['KOSPI200'], label='KOSPI200')\n",
    "plt.legend(loc=0)\n",
    "plt.grid(True, color='0.7', linestyle=':', linewidth=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(7,7))\n",
    "plt.scatter(df_ratio_2021_now['S&P500'], df_ratio_2021_now['KOSPI200'], marker='.')\n",
    "plt.grid(True, color='0.7', linestyle=':', linewidth=1)\n",
    "plt.xlabel('S&P500')\n",
    "plt.ylabel('KOSPI200')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "x = df_ratio_2021_now['S&P500']\n",
    "y = df_ratio_2021_now['KOSPI200']\n",
    "\n",
    "# 1개 컬럼 np.array로 변환\n",
    "independent_var = np.array(x).reshape(-1, 1)\n",
    "dependent_var = np.array(y).reshape(-1, 1)\n",
    "\n",
    "# Linear Regression\n",
    "regr = LinearRegression()\n",
    "regr.fit(independent_var, dependent_var)\n",
    "\n",
    "result = {'Slope':regr.coef_[0,0], 'Intercept':regr.intercept_[0], 'R^2':regr.score(independent_var, dependent_var) }\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(7,7))\n",
    "plt.scatter(independent_var, dependent_var, marker='.', color='skyblue')\n",
    "plt.plot(independent_var, regr.predict(independent_var), color='r', linewidth=3)\n",
    "plt.grid(True, color='0.7', linestyle=':', linewidth=1)\n",
    "plt.xlabel('S&P500')\n",
    "plt.ylabel('KOSPI200')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
